{"nbformat":4,"nbformat_minor":4,"metadata":{"notebookPath":"kws-homework/kws.ipynb","accelerator":"GPU","language_info":{"version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","file_extension":".py"},"notebookId":"3e35d411-455e-4fc7-abbb-fe61cfdaed88","colab":{"name":"seminar.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"}},"cells":[{"cell_type":"markdown","source":"# Import and misc","metadata":{"cellId":"5e2enn8gcfcdcgemhdv7tw","id":"_lhrn5O-qUYZ"}},{"cell_type":"code","source":"%pip install torchaudio==0.9.1","metadata":{"outputId":"4f06a169-1ef1-49c5-f849-9dae932f8eb2","id":"meO-Mp9jiAFC","cellId":"yi282fxdfp9a88i1dzv9pi","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":486}},"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torchaudio==0.9.1 in /home/jupyter/.local/lib/python3.7/site-packages (0.9.1)\nRequirement already satisfied: torch==1.9.1 in /home/jupyter/.local/lib/python3.7/site-packages (from torchaudio==0.9.1) (1.9.1)\nRequirement already satisfied: typing-extensions in /kernel/lib/python3.7/site-packages (from torch==1.9.1->torchaudio==0.9.1) (3.10.0.2)\n\u001B[33mWARNING: You are using pip version 21.0.1; however, version 21.3.1 is available.\nYou should consider upgrading via the '/usr/local/bin/python3 -m pip install --upgrade pip' command.\u001B[0m\n"}],"execution_count":34},{"cell_type":"code","source":"#!g1.1\nfrom typing import Tuple, Union, List, Callable, Optional\nfrom tqdm import tqdm\nfrom itertools import islice\nimport pathlib\nimport dataclasses\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nfrom torch import distributions\nfrom torch.utils.data import DataLoader, Dataset, WeightedRandomSampler\nfrom torch.nn.utils.rnn import pad_sequence\n\nimport torchaudio\nfrom IPython import display as display_\n\ntorch.manual_seed(42)\nnp.random.seed(42)","metadata":{"id":"bbUpoArCqUYa","cellId":"2mdihkk16q2r5q4ageuprf","trusted":true},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":"# Task","metadata":{"cellId":"rf77fj57is6s7r7roaf2d","id":"812GwLfqqUYf"}},{"cell_type":"markdown","source":"In this notebook we will implement a model for finding a keyword in a stream.\n\nWe will implement the version with CRNN because it is easy and improves the model. \n(from https://www.dropbox.com/s/22ah2ba7dug6pzw/KWS_Attention.pdf)","metadata":{"cellId":"gtxjm07h83vodd6nkbb4en","id":"i1DuQIyRqUYf"}},{"cell_type":"code","source":"#!g1.1\n@dataclasses.dataclass\nclass TaskConfig:\n    keyword: str = 'sheila'  # We will use 1 key word -- 'sheila'\n    batch_size: int = 128\n    learning_rate: float = 3e-4\n    weight_decay: float = 1e-5\n    num_epochs: int = 50\n    n_mels: int = 40\n    cnn_out_channels: int = 8\n    kernel_size: Tuple[int, int] = (5, 20)\n    stride: Tuple[int, int] = (2, 8)\n    hidden_size: int = 64\n    gru_num_layers: int = 2\n    bidirectional: bool = False\n    num_classes: int = 2\n    sample_rate: int = 16000\n    device: torch.device = torch.device(\n        'cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"8PdhApeEh9pH","cellId":"r1x3mjzmmhawdqs4bpgaf","trusted":true},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"# Data","metadata":{"cellId":"pcmenfvfw1jqunvnkope7i","id":"KA1gPmE1h9pI"}},{"cell_type":"code","source":"# !wget http://download.tensorflow.org/data/speech_commands_v0.01.tar.gz -O speech_commands_v0.01.tar.gz\n# !mkdir speech_commands && tar -C speech_commands -xvzf speech_commands_v0.01.tar.gz 1> log","metadata":{"outputId":"e7adf9cf-5348-4821-dff6-251e29a1b994","id":"Y2N8zcx9MF1X","cellId":"jeq6um3hkgpkkc3i0notm","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"#!g1.1\nclass SpeechCommandDataset(Dataset):\n\n    def __init__(\n        self,\n        transform: Optional[Callable] = None,\n        path2dir: str = None,\n        keywords: Union[str, List[str]] = None,\n        csv: Optional[pd.DataFrame] = None\n    ):        \n        self.transform = transform\n\n        if csv is None:\n            path2dir = pathlib.Path(path2dir)\n            keywords = keywords if isinstance(keywords, list) else [keywords]\n            \n            all_keywords = [\n                p.stem for p in path2dir.glob('*')\n                if p.is_dir() and not p.stem.startswith('_')\n            ]\n\n            triplets = []\n            for keyword in all_keywords:\n                paths = (path2dir / keyword).rglob('*.wav')\n                if keyword in keywords:\n                    for path2wav in paths:\n                        triplets.append((path2wav.as_posix(), keyword, 1))\n                else:\n                    for path2wav in paths:\n                        triplets.append((path2wav.as_posix(), keyword, 0))\n            \n            self.csv = pd.DataFrame(\n                triplets,\n                columns=['path', 'keyword', 'label']\n            )\n\n        else:\n            self.csv = csv\n    \n    def __getitem__(self, index: int):\n        instance = self.csv.iloc[index]\n\n        path2wav = instance['path']\n        wav, sr = torchaudio.load(path2wav)\n        wav = wav.sum(dim=0)\n        \n        if self.transform:\n            wav = self.transform(wav)\n\n        return {\n            'wav': wav,\n            'keywors': instance['keyword'],\n            'label': instance['label']\n        }\n\n    def __len__(self):\n        return len(self.csv)","metadata":{"id":"12wBTK0mNUsG","cellId":"fwqjo2jldkhlq69dhyk6r","trusted":true},"outputs":[],"execution_count":39},{"cell_type":"code","source":"#!g1.1\ndataset = SpeechCommandDataset(\n    path2dir='speech_commands', keywords=TaskConfig.keyword\n)","metadata":{"id":"-1rVkT81Pk90","cellId":"6dav03muedps7xdww9e3n","trusted":true},"outputs":[],"execution_count":40},{"cell_type":"code","source":"#!g1.1\ndataset.csv.sample(5)","metadata":{"outputId":"92c8ef89-97ac-43af-a29a-fab2c8cf6100","id":"DFwhAXdfQLIA","cellId":"8a59qgb849vxoi3trgwry","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":204}},"outputs":[{"output_type":"display_data","data":{"text/plain":"                                              path keyword  label\n58234   speech_commands/stop/f8ad3941_nohash_0.wav    stop      0\n14087   speech_commands/left/173ce2be_nohash_0.wav    left      0\n1119   speech_commands/eight/102192fd_nohash_1.wav   eight      0\n4759    speech_commands/nine/15c563d7_nohash_4.wav    nine      0\n29582    speech_commands/dog/748cb308_nohash_1.wav     dog      0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>path</th>\n      <th>keyword</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>58234</th>\n      <td>speech_commands/stop/f8ad3941_nohash_0.wav</td>\n      <td>stop</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>14087</th>\n      <td>speech_commands/left/173ce2be_nohash_0.wav</td>\n      <td>left</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1119</th>\n      <td>speech_commands/eight/102192fd_nohash_1.wav</td>\n      <td>eight</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4759</th>\n      <td>speech_commands/nine/15c563d7_nohash_4.wav</td>\n      <td>nine</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>29582</th>\n      <td>speech_commands/dog/748cb308_nohash_1.wav</td>\n      <td>dog</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":41},{"cell_type":"markdown","source":"### Augmentations","metadata":{"cellId":"vhorjvit57etpzytpvxe","id":"LUxfDJw1qUYi"}},{"cell_type":"code","source":"#!g1.1\nclass AugsCreation:\n\n    def __init__(self):\n        self.background_noises = [\n            'speech_commands/_background_noise_/white_noise.wav',\n            'speech_commands/_background_noise_/dude_miaowing.wav',\n            'speech_commands/_background_noise_/doing_the_dishes.wav',\n            'speech_commands/_background_noise_/exercise_bike.wav',\n            'speech_commands/_background_noise_/pink_noise.wav',\n            'speech_commands/_background_noise_/running_tap.wav'\n        ]\n\n        self.noises = [\n            torchaudio.load(p)[0].squeeze()\n            for p in self.background_noises\n        ]\n\n    def add_rand_noise(self, audio):\n\n        # randomly choose noise\n        noise_num = torch.randint(low=0, high=len(\n            self.background_noises), size=(1,)).item()\n        noise = self.noises[noise_num]\n\n        noise_level = torch.Tensor([1])  # [0, 40]\n\n        noise_energy = torch.norm(noise)\n        audio_energy = torch.norm(audio)\n        alpha = (audio_energy / noise_energy) * \\\n            torch.pow(10, -noise_level / 20)\n\n        start = torch.randint(\n            low=0,\n            high=max(int(noise.size(0) - audio.size(0) - 1), 1),\n            size=(1,)\n        ).item()\n        noise_sample = noise[start: start + audio.size(0)]\n\n        audio_new = audio + alpha * noise_sample\n        audio_new.clamp_(-1, 1)\n        return audio_new\n\n    def __call__(self, wav):\n        aug_num = torch.randint(low=0, high=4, size=(1,)).item()   # choose 1 random aug from augs\n        augs = [\n            lambda x: x,\n            lambda x: (x + distributions.Normal(0, 0.01).sample(x.size())).clamp_(-1, 1),\n            lambda x: torchaudio.transforms.Vol(.25)(x),\n            lambda x: self.add_rand_noise(x)\n        ]\n\n        return augs[aug_num](wav)","metadata":{"id":"dkmkxPWQqUYe","jupyter":{"source_hidden":true},"cellId":"5dwg9j4f2zd63p4b8ouzkx","trusted":true},"outputs":[],"execution_count":42},{"cell_type":"code","source":"#!g1.1\nindexes = torch.randperm(len(dataset))\ntrain_indexes = indexes[:int(len(dataset) * 0.8)]\nval_indexes = indexes[int(len(dataset) * 0.8):]\n\ntrain_df = dataset.csv.iloc[train_indexes].reset_index(drop=True)\nval_df = dataset.csv.iloc[val_indexes].reset_index(drop=True)","metadata":{"id":"ClWThxyYh9pM","jupyter":{"source_hidden":true},"cellId":"meuiwn7oazfikzsxbzly","trusted":true},"outputs":[],"execution_count":43},{"cell_type":"code","source":"#!g1.1\n# Sample is a dict of utt, word and label\ntrain_set = SpeechCommandDataset(csv=train_df, transform=AugsCreation())\nval_set = SpeechCommandDataset(csv=val_df)","metadata":{"id":"PDPLht5fqUYe","jupyter":{"source_hidden":true},"cellId":"p01vkc8qf9gkb237ncp0g","trusted":true},"outputs":[],"execution_count":44},{"cell_type":"code","source":"","metadata":{"cellId":"fnl456zbslwnh49oinqm3r","id":"mmrJd8WIhkLP"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Sampler for oversampling:","metadata":{"cellId":"tlv68756yafx4r4t1tj58","id":"2vbPDqd6qUYj"}},{"cell_type":"code","source":"# We should provide to WeightedRandomSampler _weight for every sample_; by default it is 1/len(target)\n#!g1.1\n\ndef get_sampler(target):\n    class_sample_count = np.array(\n        [len(np.where(target == t)[0]) for t in np.unique(target)])   # for every class count it's number of occ.\n    weight = 1. / class_sample_count\n    samples_weight = np.array([weight[t] for t in target])\n    samples_weight = torch.from_numpy(samples_weight)\n    samples_weigth = samples_weight.float()\n    sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n    return sampler","metadata":{"id":"rfnjRKo2qUYj","cellId":"1u7a0d8vox8dnpcue32ev5","trusted":true},"outputs":[],"execution_count":45},{"cell_type":"code","source":"#!g1.1\ntrain_sampler = get_sampler(train_set.csv['label'].values)\nval_sampler = get_sampler(val_set.csv['label'].values)","metadata":{"id":"UM8gLmHeqUYj","cellId":"7iuad6ms0qb3xulehlyk2","trusted":true},"outputs":[],"execution_count":46},{"cell_type":"code","source":"#!g1.1\nclass Collator:\n    \n    def __call__(self, data):\n        wavs = []\n        labels = []    \n\n        for el in data:\n            wavs.append(el['wav'])\n            labels.append(el['label'])\n\n        # torch.nn.utils.rnn.pad_sequence takes list(Tensors) and returns padded (with 0.0) Tensor\n        wavs = pad_sequence(wavs, batch_first=True)    \n        labels = torch.Tensor(labels).long()\n        return wavs, labels","metadata":{"id":"lyBqbxp0h9pO","cellId":"smjcccf204pp7a9vsyoz4g","trusted":true},"outputs":[],"execution_count":47},{"cell_type":"markdown","source":"###  Dataloaders","metadata":{"cellId":"e3agl2pdtefr791vlh3fdq","id":"e8G9xPRVqUYk"}},{"cell_type":"code","source":"#!g1.1\n# wtf is going on in this cell? Nothing special, just Datasphere things.\n\n# Here we are obliged to use shuffle=False because of our sampler with randomness inside.\ntrain_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n                          shuffle=False, collate_fn=Collator(),\n                          sampler=train_sampler,\n                          num_workers=0, pin_memory=True)\n\nval_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n                        shuffle=False, collate_fn=Collator(),\n                        sampler=val_sampler,\n                        num_workers=0, pin_memory=True)\n\nnext(iter(train_loader))\nnext(iter(val_loader))\n\ntrain_loader = DataLoader(train_set, batch_size=TaskConfig.batch_size,\n                          shuffle=False, collate_fn=Collator(),\n                          sampler=train_sampler,\n                          num_workers=2, pin_memory=True)\n\nval_loader = DataLoader(val_set, batch_size=TaskConfig.batch_size,\n                        shuffle=False, collate_fn=Collator(),\n                        sampler=val_sampler,\n                        num_workers=2, pin_memory=True)","metadata":{"id":"6wGBMcQiqUYk","cellId":"spwlkkj9hzk5w1q6o2g0rw","trusted":true},"outputs":[],"execution_count":140},{"cell_type":"markdown","source":"### Creating MelSpecs on GPU for speeeed: ","metadata":{"cellId":"8m19k1ebaclf0zu34jfdqp","id":"kTlsn6cpqUYk"}},{"cell_type":"code","source":"#!g1.1\nclass LogMelspec:\n\n    def __init__(self, is_train, config):\n        # with augmentations\n        if is_train:\n            self.melspec = nn.Sequential(\n                torchaudio.transforms.MelSpectrogram(\n                    sample_rate=config.sample_rate,\n                    n_fft=400,\n                    win_length=400,\n                    hop_length=160,\n                    n_mels=config.n_mels\n                ),\n                torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n                torchaudio.transforms.TimeMasking(time_mask_param=35),\n            ).to(config.device)\n\n        # no augmentations\n        else:\n            self.melspec = torchaudio.transforms.MelSpectrogram(\n                sample_rate=config.sample_rate,\n                n_fft=400,\n                win_length=400,\n                hop_length=160,\n                n_mels=config.n_mels\n            ).to(config.device)\n\n    def __call__(self, batch):\n        # already on device\n        return torch.log(self.melspec(batch).clamp_(min=1e-9, max=1e9))","metadata":{"id":"pRXMt6it56fW","cellId":"qv7aki1mf9n3cgb7yw1edq","trusted":true},"outputs":[],"execution_count":49},{"cell_type":"code","source":"#!g1.1\nmelspec_train = LogMelspec(is_train=True, config=TaskConfig)\nmelspec_val = LogMelspec(is_train=False, config=TaskConfig)","metadata":{"id":"Pqkz4_gn8BiF","cellId":"n8ldolyq3pd3poi57urr","trusted":true},"outputs":[],"execution_count":50},{"cell_type":"markdown","source":"### Quality measurment functions:","metadata":{"cellId":"wktprz3g8tvu0tfyljbri","id":"zoAxmihY8yxr"}},{"cell_type":"code","source":"#!g1.1\n# FA - true: 0, model: 1\n# FR - true: 1, model: 0\n\ndef count_FA_FR(preds, labels):\n    FA = torch.sum(preds[labels == 0])\n    FR = torch.sum(labels[preds == 0])\n    \n    # torch.numel - returns total number of elements in tensor\n    return FA.item() / torch.numel(preds), FR.item() / torch.numel(preds)","metadata":{"id":"euwD1UyuqUYk","cellId":"6mvseym8mg311lniraduo7m","trusted":true},"outputs":[],"execution_count":51},{"cell_type":"code","source":"#!g1.1\ndef get_au_fa_fr(probs, labels):\n    sorted_probs, _ = torch.sort(probs)\n    sorted_probs = torch.cat((torch.Tensor([0]), sorted_probs, torch.Tensor([1])))\n    labels = torch.cat(labels, dim=0)\n        \n    FAs, FRs = [], []\n    for prob in sorted_probs:\n        preds = (probs >= prob) * 1\n        FA, FR = count_FA_FR(preds, labels)        \n        FAs.append(FA)\n        FRs.append(FR)\n    # plt.plot(FAs, FRs)\n    # plt.show()\n\n    # ~ area under curve using trapezoidal rule\n    return -np.trapz(FRs, x=FAs)","metadata":{"id":"YHBUrkT1qUYk","cellId":"ss889hn8kgg44rjgtglao","trusted":true},"outputs":[],"execution_count":52},{"cell_type":"markdown","source":"# Model","metadata":{"cellId":"qs18r8zb8vchmncnf5cxg","id":"CcEP5cEZqUYl"}},{"cell_type":"code","source":"#!g1.1\nclass Attention(nn.Module):\n\n    def __init__(self, hidden_size: int):\n        super().__init__()\n\n        self.energy = nn.Sequential(\n            nn.Linear(hidden_size, hidden_size),\n            nn.Tanh(),\n            nn.Linear(hidden_size, 1)\n        )\n    \n    def forward(self, input):\n        energy = self.energy(input)\n        alpha = torch.softmax(energy, dim=-2)\n        return (input * alpha).sum(dim=-2)\n\nclass CRNN(nn.Module):\n\n    def __init__(self, config: TaskConfig):\n        super().__init__()\n        self.config = config\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(\n                in_channels=1, out_channels=config.cnn_out_channels,\n                kernel_size=config.kernel_size, stride=config.stride\n            ),\n            nn.Flatten(start_dim=1, end_dim=2),\n        )\n\n        self.conv_out_frequency = (config.n_mels - config.kernel_size[0]) // \\\n            config.stride[0] + 1\n        \n        self.gru = nn.GRU(\n            input_size=self.conv_out_frequency * config.cnn_out_channels,\n            hidden_size=config.hidden_size,\n            num_layers=config.gru_num_layers,\n            dropout=0.1,\n            bidirectional=config.bidirectional,\n            batch_first=True\n        )\n\n        self.attention = Attention(config.hidden_size)\n        self.classifier = nn.Linear(config.hidden_size, config.num_classes)\n    \n    def forward(self, input):\n        input = input.unsqueeze(dim=1)\n        conv_output = self.conv(input).transpose(-1, -2)\n        gru_output, _ = self.gru(conv_output)\n        contex_vector = self.attention(gru_output)\n        output = self.classifier(contex_vector)\n        return output\nconfig = TaskConfig()\nmodel = CRNN(config)\nmodel","metadata":{"outputId":"baa3467d-b1c9-4d5c-acd1-4723ed39f1b7","id":"2cP_pFIsy5p2","cellId":"uyu1mpxdbafodddb7bpif","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"CRNN(\n  (conv): Sequential(\n    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n    (1): Flatten(start_dim=1, end_dim=2)\n  )\n  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n  (attention): Attention(\n    (energy): Sequential(\n      (0): Linear(in_features=64, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=1, bias=True)\n    )\n  )\n  (classifier): Linear(in_features=64, out_features=2, bias=True)\n)"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"#!g1.1\ndef train_epoch(model, opt, loader, log_melspec, device):\n    model.train()\n    for i, (batch, labels) in tqdm(enumerate(loader), total=len(loader)):\n        batch, labels = batch.to(device), labels.to(device)\n        batch = log_melspec(batch)\n\n        opt.zero_grad()\n\n        # run model # with autocast():\n        logits = model(batch)\n        # we need probabilities so we use softmax & CE separately\n        probs = F.softmax(logits, dim=-1)\n        loss = F.cross_entropy(logits, labels)\n\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n\n        opt.step()\n\n        # logging\n        argmax_probs = torch.argmax(probs, dim=-1)\n        FA, FR = count_FA_FR(argmax_probs, labels)\n        acc = torch.sum(argmax_probs == labels) / torch.numel(argmax_probs)\n\n    return acc","metadata":{"id":"DmmSFvWaqUYn","cellId":"vv6d6cq5u4jrgaawf0bkn","trusted":true},"outputs":[],"execution_count":54},{"cell_type":"code","source":"#!g1.1\n@torch.no_grad()\ndef validation(model, loader, log_melspec, device):\n    model.eval()\n\n    val_losses, accs, FAs, FRs = [], [], [], []\n    all_probs, all_labels = [], []\n    for i, (batch, labels) in tqdm(enumerate(loader)):\n        batch, labels = batch.to(device), labels.to(device)\n        batch = log_melspec(batch)\n\n        output = model(batch)\n        # we need probabilities so we use softmax & CE separately\n        probs = F.softmax(output, dim=-1)\n        loss = F.cross_entropy(output, labels)\n\n        # logging\n        argmax_probs = torch.argmax(probs, dim=-1)\n        all_probs.append(probs[:, 1].cpu())\n        all_labels.append(labels.cpu())\n        val_losses.append(loss.item())\n        accs.append(\n            torch.sum(argmax_probs == labels).item() /  # ???\n            torch.numel(argmax_probs)\n        )\n        FA, FR = count_FA_FR(argmax_probs, labels)\n        FAs.append(FA)\n        FRs.append(FR)\n\n    # area under FA/FR curve for whole loader\n    au_fa_fr = get_au_fa_fr(torch.cat(all_probs, dim=0).cpu(), all_labels)\n    return au_fa_fr","metadata":{"id":"UIeRbn4tqUYo","cellId":"xm5zu307jchi5e69eh0f9","trusted":true},"outputs":[],"execution_count":55},{"cell_type":"code","source":"#!g1.1\nfrom collections import defaultdict\nfrom IPython.display import clear_output\nfrom matplotlib import pyplot as plt\n\nhistory = defaultdict(list)","metadata":{"id":"PpyvKwp0k3IU","cellId":"5ax8xr0rpc6fpljb5cqpcf","trusted":true},"outputs":[],"execution_count":56},{"cell_type":"markdown","source":"# Training","metadata":{"cellId":"s18njnaikso8nmemgr8q6h","id":"GSNW-nZCJ4Q0"}},{"cell_type":"code","source":"#!g1.1\nconfig = TaskConfig()\nmodel = CRNN(config).to(config.device)\n\nprint(model)\n\nopt = torch.optim.Adam(\n    model.parameters(),\n    lr=config.learning_rate,\n    weight_decay=config.weight_decay\n)","metadata":{"outputId":"deeed91e-edfe-40d3-b810-3e06905f2a5a","id":"Q8sVpHNoocgA","cellId":"w3yvjay5jafjpauo8akal","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":"CRNN(\n  (conv): Sequential(\n    (0): Conv2d(1, 8, kernel_size=(5, 20), stride=(2, 8))\n    (1): Flatten(start_dim=1, end_dim=2)\n  )\n  (gru): GRU(144, 64, num_layers=2, batch_first=True, dropout=0.1)\n  (attention): Attention(\n    (energy): Sequential(\n      (0): Linear(in_features=64, out_features=64, bias=True)\n      (1): Tanh()\n      (2): Linear(in_features=64, out_features=1, bias=True)\n    )\n  )\n  (classifier): Linear(in_features=64, out_features=2, bias=True)\n)\n"}],"execution_count":57},{"cell_type":"code","source":"#!g1.1\nsum([p.numel() for p in model.parameters()])","metadata":{"outputId":"bcbdc49f-8b90-41bd-f6a9-2964592e8494","id":"zedXm9dmINAE","cellId":"ep204wnf3341jco3g4ml25","trusted":true,"colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"70443"},"metadata":{}}],"execution_count":58},{"cell_type":"code","source":"#!g1.1\n# TRAIN\nif False:\n    for n in range(1, TaskConfig.num_epochs + 1):\n\n        train_epoch(model, opt, train_loader,\n                    melspec_train, config.device)\n\n        au_fa_fr = validation(model, val_loader,\n                              melspec_val, config.device)\n        history['val_metric'].append(au_fa_fr)\n\n        clear_output()\n        plt.plot(history['val_metric'])\n        plt.ylabel('Metric')\n        plt.xlabel('Epoch')\n        plt.grid()\n        plt.show()\n\n        print('END OF EPOCH', n)\n\n        if (au_fa_fr - 0.0002) <= 1e-5:\n            break\n    assert (history['val_metric'][-1] - 0.0002) <= 1e-5, \"Quality is not good enough\"\n    torch.save(model.state_dict(), \"model.pt\")","metadata":{"outputId":"debc5f47-e019-4b5c-d58e-802ba277bc77","id":"32oooz4lqUYo","cellId":"bimoqzzcwaqekeouthq0dt","trusted":true,"colab":{"base_uri":"https://localhost:8080/","height":315}},"outputs":[],"execution_count":59},{"cell_type":"markdown","source":"# Streaming","metadata":{"cellId":"kzr0hipsbf0b4nb38svbff"}},{"cell_type":"code","source":"#!g1.1\nmodel.load_state_dict(torch.load(\"model.pt\"))\nmodel.eval();","metadata":{"cellId":"898kudvyx7ib9ydt5xlb2t","trusted":true},"outputs":[],"execution_count":60},{"cell_type":"code","source":"#!g1.1\nclass StreamingKWS(CRNN):\n    def  __init__(self, config, window_length, step=1):\n        super().__init__(config)\n        \n        self.window_len = window_length\n        assert step % config.stride[1] == 0, f\"Step should be divisible by {self.stride}\"\n        self.step = step\n        self.cnn_buffer = torch.zeros((1, window_length, config.hidden_size), device=config.device)\n        self.rnn_in_len = (window_length-self.kernel_size[1])//self.stride[1]+1\n        self.rnn_buffer = torch.zeros((1, rnn_in_len, config.hidden_size), device=config.device)\n        self.hidden = None\n        \n    def forward(self, input, mode='whole'):\n        outputs=[]\n        if mode == 'whole':\n            input = input.unsqueeze(dim=0).unsqueeze(dim=0)\n            \n            for i in range(0, input.size(-1), self.step):\n                conv_output = self.conv(input[:,:,:,i+1-self.step:i+1]).transpose(-1, -2)\n                self.cnn_buffer = torch.cat((self.cnn_buffer, conv_output), dim=1)[:,:-self.window_len]\n                \n                gru_output, self.hidden = self.gru(conv_output, self.hidden)\n                self.rnn_buffer = torch.cat((self.rnn_buffer, gru_output), dim=1)[:,:-self.rnn_in_len]\n                \n                contex_vector = self.attention(self.rnn_buffer)\n                output = self.classifier(contex_vector)\n                output = F.softmax(output, dim=-1)\n                outputs.append(output[0,1].item())\n            self.hidden = None\n        return outputs\n    \n#     def proccess_whole(self, input):\n        \n#     def _process_window(self, window):\n#         contex_vector = self.model.contex_vector(window)\n        \n#         probs, attention = F.softmax(output, dim=-1)\n#         return probs[0,1]\n    \n#     def contex_vector(self, input):\n#         input = input.unsqueeze(dim=1)\n#         conv_output = self.conv(input).transpose(-1, -2)\n#         gru_output, _ = self.gru(conv_output)\n#         contex_vector = self.attention(gru_output)\n#         return contex_vector\n#     def classify(self, contex_vector):\n#         output = self.classifier(contex_vector)\n#         return output","metadata":{"cellId":"yd1yf4fcvgcev28xwci6qs","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\nstreaming_model = StreamingKWS(model.config, 100).to(model.config.device)\nstreaming_model.load_state_dict(torch.load(\"model.pt\"))\nstreaming_model.eval();","metadata":{"cellId":"yk4g7uqfd5gqj9pi7mhprl","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#!g1.1\ndevice=model.config.device\nfor batch, labels in train_loader:\n    batch, labels = batch[0:8].flatten(), labels[0:8]\n    print(labels)\n#     batch = batch.unsqueeze(dim=0)\n    batch, labels = batch.to(device), labels.to(device)\n    batch = melspec_val(batch)\n    output = streaming_model(batch)\n#     plt.imshow(batch.cpu().numpy())\n    plt.plot(output)\n    plt.show()\n    print(output)\n    break","metadata":{"cellId":"qrkgirn8w8h2gfgs9q9itk","trusted":true},"outputs":[{"output_type":"stream","name":"stderr","text":"/kernel/lib/python3.7/site-packages/ml_kernel/ignored_keyboard_interrupt.py:16: UserWarning: Kernel cannot be interrupted during state load\n  warnings.warn(self._warn_message)\n/kernel/lib/python3.7/site-packages/ml_kernel/ignored_keyboard_interrupt.py:16: UserWarning: Kernel cannot be interrupted during state load\n  warnings.warn(self._warn_message)\n/kernel/lib/python3.7/site-packages/ml_kernel/ignored_keyboard_interrupt.py:16: UserWarning: Kernel cannot be interrupted during state load\n  warnings.warn(self._warn_message)\n/kernel/lib/python3.7/site-packages/ml_kernel/ignored_keyboard_interrupt.py:16: UserWarning: Kernel cannot be interrupted during state load\n  warnings.warn(self._warn_message)\n"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001B[0;31m---------------------------------------------------------------------------\u001B[0m","\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)","\u001B[0;32m<ipython-input-7-d65c89f761f6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconfig\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0;32mfor\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mtrain_loader\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m     \u001B[0mbatch\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mflatten\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlabels\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;31m#     batch = batch.unsqueeze(dim=0)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    519\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sampler_iter\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    520\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 521\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    522\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    523\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1184\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1185\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_shutdown\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1186\u001B[0;31m             \u001B[0midx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1187\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_tasks_outstanding\u001B[0m \u001B[0;34m-=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1188\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_get_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1140\u001B[0m         \u001B[0;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1141\u001B[0m             \u001B[0;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory_thread\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_alive\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1142\u001B[0;31m                 \u001B[0msuccess\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_try_get_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1143\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0msuccess\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1144\u001B[0m                     \u001B[0;32mreturn\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m~/.local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_try_get_data\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    988\u001B[0m         \u001B[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    989\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 990\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_data_queue\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    991\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    992\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/queue.py\u001B[0m in \u001B[0;36mget\u001B[0;34m(self, block, timeout)\u001B[0m\n\u001B[1;32m    177\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0mremaining\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0.0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    178\u001B[0m                         \u001B[0;32mraise\u001B[0m \u001B[0mEmpty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 179\u001B[0;31m                     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnot_empty\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwait\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mremaining\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    180\u001B[0m             \u001B[0mitem\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    181\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnot_full\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnotify\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;32m/usr/lib/python3.7/threading.py\u001B[0m in \u001B[0;36mwait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    298\u001B[0m             \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    299\u001B[0m                 \u001B[0;32mif\u001B[0m \u001B[0mtimeout\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 300\u001B[0;31m                     \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    301\u001B[0m                 \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    302\u001B[0m                     \u001B[0mgotit\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mwaiter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0macquire\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n","\u001B[0;31mKeyboardInterrupt\u001B[0m: "]}],"execution_count":148},{"cell_type":"code","source":"#!g1.1\n","metadata":{"cellId":"1zojars2lt8qqerd2zvnq"},"outputs":[],"execution_count":null}]}